{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe\n",
    "caffe.set_mode_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "--2020-09-22 12:19:27--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 104.28.7.204, 104.28.6.204, 172.67.171.76, ...\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|104.28.7.204|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9912422 (9.5M) [application/x-gzip]\n",
      "Saving to: 'train-images-idx3-ubyte.gz'\n",
      "\n",
      "train-images-idx3-u 100%[===================>]   9.45M  4.64MB/s    in 2.0s    \n",
      "\n",
      "2020-09-22 12:19:30 (4.64 MB/s) - 'train-images-idx3-ubyte.gz' saved [9912422/9912422]\n",
      "\n",
      "--2020-09-22 12:19:30--  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 104.28.7.204, 104.28.6.204, 172.67.171.76, ...\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|104.28.7.204|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28881 (28K) [application/x-gzip]\n",
      "Saving to: 'train-labels-idx1-ubyte.gz'\n",
      "\n",
      "train-labels-idx1-u 100%[===================>]  28.20K   165KB/s    in 0.2s    \n",
      "\n",
      "2020-09-22 12:19:31 (165 KB/s) - 'train-labels-idx1-ubyte.gz' saved [28881/28881]\n",
      "\n",
      "--2020-09-22 12:19:31--  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 104.28.7.204, 104.28.6.204, 172.67.171.76, ...\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|104.28.7.204|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1648877 (1.6M) [application/x-gzip]\n",
      "Saving to: 't10k-images-idx3-ubyte.gz'\n",
      "\n",
      "t10k-images-idx3-ub 100%[===================>]   1.57M  1.40MB/s    in 1.1s    \n",
      "\n",
      "2020-09-22 12:19:32 (1.40 MB/s) - 't10k-images-idx3-ubyte.gz' saved [1648877/1648877]\n",
      "\n",
      "--2020-09-22 12:19:32--  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 104.28.7.204, 104.28.6.204, 172.67.171.76, ...\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|104.28.7.204|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4542 (4.4K) [application/x-gzip]\n",
      "Saving to: 't10k-labels-idx1-ubyte.gz'\n",
      "\n",
      "t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-09-22 12:19:33 (144 MB/s) - 't10k-labels-idx1-ubyte.gz' saved [4542/4542]\n",
      "\n",
      "Creating lmdb...\n",
      "I0922 12:19:33.325053    47 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb\n",
      "I0922 12:19:33.325592    47 convert_mnist_data.cpp:88] A total of 60000 items.\n",
      "I0922 12:19:33.325628    47 convert_mnist_data.cpp:89] Rows: 28 Cols: 28\n",
      "I0922 12:19:33.661387    47 convert_mnist_data.cpp:108] Processed 60000 files.\n",
      "I0922 12:19:33.705598    49 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb\n",
      "I0922 12:19:33.705837    49 convert_mnist_data.cpp:88] A total of 10000 items.\n",
      "I0922 12:19:33.705849    49 convert_mnist_data.cpp:89] Rows: 28 Cols: 28\n",
      "I0922 12:19:33.759439    49 convert_mnist_data.cpp:108] Processed 10000 files.\n",
      "Done.\n",
      "I0922 12:19:33.810467    55 caffe.cpp:211] Use CPU.\n",
      "I0922 12:19:33.810818    55 solver.cpp:44] Initializing solver from parameters: \n",
      "test_iter: 100\n",
      "test_interval: 500\n",
      "base_lr: 0.01\n",
      "display: 100\n",
      "max_iter: 10000\n",
      "lr_policy: \"inv\"\n",
      "gamma: 0.0001\n",
      "power: 0.75\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0005\n",
      "snapshot: 5000\n",
      "snapshot_prefix: \"examples/mnist/lenet\"\n",
      "solver_mode: CPU\n",
      "net: \"examples/mnist/lenet_train_test.prototxt\"\n",
      "train_state {\n",
      "  level: 0\n",
      "  stage: \"\"\n",
      "}\n",
      "I0922 12:19:33.811442    55 solver.cpp:87] Creating training net from net file: examples/mnist/lenet_train_test.prototxt\n",
      "I0922 12:19:33.811940    55 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist\n",
      "I0922 12:19:33.812265    55 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy\n",
      "I0922 12:19:33.812366    55 net.cpp:51] Initializing net from parameters: \n",
      "name: \"LeNet\"\n",
      "state {\n",
      "  phase: TRAIN\n",
      "  level: 0\n",
      "  stage: \"\"\n",
      "}\n",
      "layer {\n",
      "  name: \"mnist\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TRAIN\n",
      "  }\n",
      "  transform_param {\n",
      "    scale: 0.00390625\n",
      "  }\n",
      "  data_param {\n",
      "    source: \"examples/mnist/mnist_train_lmdb\"\n",
      "    batch_size: 64\n",
      "    backend: LMDB\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 20\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 50\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ip1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"ip1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 500\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 10\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I0922 12:19:33.813621    55 layer_factory.hpp:77] Creating layer mnist\n",
      "I0922 12:19:33.814275    55 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb\n",
      "I0922 12:19:33.814553    55 net.cpp:84] Creating Layer mnist\n",
      "I0922 12:19:33.814677    55 net.cpp:380] mnist -> data\n",
      "I0922 12:19:33.814852    55 net.cpp:380] mnist -> label\n",
      "I0922 12:19:33.815223    55 data_layer.cpp:45] output data size: 64,1,28,28\n",
      "I0922 12:19:33.815570    55 net.cpp:122] Setting up mnist\n",
      "I0922 12:19:33.815598    55 net.cpp:129] Top shape: 64 1 28 28 (50176)\n",
      "I0922 12:19:33.815632    55 net.cpp:129] Top shape: 64 (64)\n",
      "I0922 12:19:33.815802    55 net.cpp:137] Memory required for data: 200960\n",
      "I0922 12:19:33.815829    55 layer_factory.hpp:77] Creating layer conv1\n",
      "I0922 12:19:33.815861    55 net.cpp:84] Creating Layer conv1\n",
      "I0922 12:19:33.815891    55 net.cpp:406] conv1 <- data\n",
      "I0922 12:19:33.815922    55 net.cpp:380] conv1 -> conv1\n",
      "I0922 12:19:33.816148    55 net.cpp:122] Setting up conv1\n",
      "I0922 12:19:33.816174    55 net.cpp:129] Top shape: 64 20 24 24 (737280)\n",
      "I0922 12:19:33.816198    55 net.cpp:137] Memory required for data: 3150080\n",
      "I0922 12:19:33.816229    55 layer_factory.hpp:77] Creating layer pool1\n",
      "I0922 12:19:33.816251    55 net.cpp:84] Creating Layer pool1\n",
      "I0922 12:19:33.816287    55 net.cpp:406] pool1 <- conv1\n",
      "I0922 12:19:33.816515    55 net.cpp:380] pool1 -> pool1\n",
      "I0922 12:19:33.817535    55 net.cpp:122] Setting up pool1\n",
      "I0922 12:19:33.817559    55 net.cpp:129] Top shape: 64 20 12 12 (184320)\n",
      "I0922 12:19:33.817577    55 net.cpp:137] Memory required for data: 3887360\n",
      "I0922 12:19:33.817598    55 layer_factory.hpp:77] Creating layer conv2\n",
      "I0922 12:19:33.817618    55 net.cpp:84] Creating Layer conv2\n",
      "I0922 12:19:33.817642    55 net.cpp:406] conv2 <- pool1\n",
      "I0922 12:19:33.817662    55 net.cpp:380] conv2 -> conv2\n",
      "I0922 12:19:33.818197    55 net.cpp:122] Setting up conv2\n",
      "I0922 12:19:33.818231    55 net.cpp:129] Top shape: 64 50 8 8 (204800)\n",
      "I0922 12:19:33.818254    55 net.cpp:137] Memory required for data: 4706560\n",
      "I0922 12:19:33.818295    55 layer_factory.hpp:77] Creating layer pool2\n",
      "I0922 12:19:33.818325    55 net.cpp:84] Creating Layer pool2\n",
      "I0922 12:19:33.818559    55 net.cpp:406] pool2 <- conv2\n",
      "I0922 12:19:33.818610    55 net.cpp:380] pool2 -> pool2\n",
      "I0922 12:19:33.818661    55 net.cpp:122] Setting up pool2\n",
      "I0922 12:19:33.818722    55 net.cpp:129] Top shape: 64 50 4 4 (51200)\n",
      "I0922 12:19:33.818866    55 net.cpp:137] Memory required for data: 4911360\n",
      "I0922 12:19:33.818894    55 layer_factory.hpp:77] Creating layer ip1\n",
      "I0922 12:19:33.818918    55 net.cpp:84] Creating Layer ip1\n",
      "I0922 12:19:33.819167    55 net.cpp:406] ip1 <- pool2\n",
      "I0922 12:19:33.819195    55 net.cpp:380] ip1 -> ip1\n",
      "I0922 12:19:33.822634    55 net.cpp:122] Setting up ip1\n",
      "I0922 12:19:33.822799    55 net.cpp:129] Top shape: 64 500 (32000)\n",
      "I0922 12:19:33.822835    55 net.cpp:137] Memory required for data: 5039360\n",
      "I0922 12:19:33.822880    55 layer_factory.hpp:77] Creating layer relu1\n",
      "I0922 12:19:33.822916    55 net.cpp:84] Creating Layer relu1\n",
      "I0922 12:19:33.822942    55 net.cpp:406] relu1 <- ip1\n",
      "I0922 12:19:33.822971    55 net.cpp:367] relu1 -> ip1 (in-place)\n",
      "I0922 12:19:33.823067    55 net.cpp:122] Setting up relu1\n",
      "I0922 12:19:33.823168    55 net.cpp:129] Top shape: 64 500 (32000)\n",
      "I0922 12:19:33.823220    55 net.cpp:137] Memory required for data: 5167360\n",
      "I0922 12:19:33.823267    55 layer_factory.hpp:77] Creating layer ip2\n",
      "I0922 12:19:33.823307    55 net.cpp:84] Creating Layer ip2\n",
      "I0922 12:19:33.823336    55 net.cpp:406] ip2 <- ip1\n",
      "I0922 12:19:33.823359    55 net.cpp:380] ip2 -> ip2\n",
      "I0922 12:19:33.823468    55 net.cpp:122] Setting up ip2\n",
      "I0922 12:19:33.823525    55 net.cpp:129] Top shape: 64 10 (640)\n",
      "I0922 12:19:33.823555    55 net.cpp:137] Memory required for data: 5169920\n",
      "I0922 12:19:33.823588    55 layer_factory.hpp:77] Creating layer loss\n",
      "I0922 12:19:33.823639    55 net.cpp:84] Creating Layer loss\n",
      "I0922 12:19:33.823670    55 net.cpp:406] loss <- ip2\n",
      "I0922 12:19:33.823702    55 net.cpp:406] loss <- label\n",
      "I0922 12:19:33.823731    55 net.cpp:380] loss -> loss\n",
      "I0922 12:19:33.823765    55 layer_factory.hpp:77] Creating layer loss\n",
      "I0922 12:19:33.823807    55 net.cpp:122] Setting up loss\n",
      "I0922 12:19:33.823830    55 net.cpp:129] Top shape: (1)\n",
      "I0922 12:19:33.823849    55 net.cpp:132]     with loss weight 1\n",
      "I0922 12:19:33.823889    55 net.cpp:137] Memory required for data: 5169924\n",
      "I0922 12:19:33.823909    55 net.cpp:198] loss needs backward computation.\n",
      "I0922 12:19:33.823941    55 net.cpp:198] ip2 needs backward computation.\n",
      "I0922 12:19:33.824020    55 net.cpp:198] relu1 needs backward computation.\n",
      "I0922 12:19:33.824045    55 net.cpp:198] ip1 needs backward computation.\n",
      "I0922 12:19:33.824066    55 net.cpp:198] pool2 needs backward computation.\n",
      "I0922 12:19:33.824082    55 net.cpp:198] conv2 needs backward computation.\n",
      "I0922 12:19:33.824098    55 net.cpp:198] pool1 needs backward computation.\n",
      "I0922 12:19:33.824112    55 net.cpp:198] conv1 needs backward computation.\n",
      "I0922 12:19:33.824131    55 net.cpp:200] mnist does not need backward computation.\n",
      "I0922 12:19:33.824143    55 net.cpp:242] This network produces output loss\n",
      "I0922 12:19:33.824175    55 net.cpp:255] Network initialization done.\n",
      "I0922 12:19:33.824353    55 solver.cpp:172] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt\n",
      "I0922 12:19:33.824391    55 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist\n",
      "I0922 12:19:33.824504    55 net.cpp:51] Initializing net from parameters: \n",
      "name: \"LeNet\"\n",
      "state {\n",
      "  phase: TEST\n",
      "}\n",
      "layer {\n",
      "  name: \"mnist\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  transform_param {\n",
      "    scale: 0.00390625\n",
      "  }\n",
      "  data_param {\n",
      "    source: \"examples/mnist/mnist_test_lmdb\"\n",
      "    batch_size: 100\n",
      "    backend: LMDB\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 20\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 50\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer {\r\n",
      "  name: \"pool2\"\r\n",
      "  type: \"Pooling\"\r\n",
      "  bottom: \"conv2\"\r\n",
      "  top: \"pool2\"\r\n",
      "  pooling_param {\r\n",
      "    pool: MAX\r\n",
      "    kernel_size: 2\r\n",
      "    stride: 2\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"ip1\"\r\n",
      "  type: \"InnerProduct\"\r\n",
      "  bottom: \"pool2\"\r\n",
      "  top: \"ip1\"\r\n",
      "  param {\r\n",
      "    lr_mult: 1\r\n",
      "  }\r\n",
      "  param {\r\n",
      "    lr_mult: 2\r\n",
      "  }\r\n",
      "  inner_product_param {\r\n",
      "    num_output: 500\r\n",
      "    weight_filler {\r\n",
      "      type: \"xavier\"\r\n",
      "    }\r\n",
      "    bias_filler {\r\n",
      "      type: \"constant\"\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"relu1\"\r\n",
      "  type: \"ReLU\"\r\n",
      "  bottom: \"ip1\"\r\n",
      "  top: \"ip1\"\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"ip2\"\r\n",
      "  type: \"InnerProduct\"\r\n",
      "  bottom: \"ip1\"\r\n",
      "  top: \"ip2\"\r\n",
      "  param {\r\n",
      "    lr_mult: 1\r\n",
      "  }\r\n",
      "  param {\r\n",
      "    lr_mult: 2\r\n",
      "  }\r\n",
      "  inner_product_param {\r\n",
      "    num_output: 10\r\n",
      "    weight_filler {\r\n",
      "      type: \"xavier\"\r\n",
      "    }\r\n",
      "    bias_filler {\r\n",
      "      type: \"constant\"\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"accuracy\"\r\n",
      "  type: \"Accuracy\"\r\n",
      "  bottom: \"ip2\"\r\n",
      "  bottom: \"label\"\r\n",
      "  top: \"accuracy\"\r\n",
      "  include {\r\n",
      "    phase: TEST\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"loss\"\r\n",
      "  type: \"SoftmaxWithLoss\"\r\n",
      "  bottom: \"ip2\"\r\n",
      "  bottom: \"label\"\r\n",
      "  top: \"loss\"\r\n",
      "}\r\n",
      "I0922 12:19:33.825356    55 layer_factory.hpp:77] Creating layer mnist\r\n",
      "I0922 12:19:33.827147    55 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb\r\n",
      "I0922 12:19:33.827275    55 net.cpp:84] Creating Layer mnist\r\n",
      "I0922 12:19:33.827373    55 net.cpp:380] mnist -> data\r\n",
      "I0922 12:19:33.827487    55 net.cpp:380] mnist -> label\r\n",
      "I0922 12:19:33.827566    55 data_layer.cpp:45] output data size: 100,1,28,28\r\n",
      "I0922 12:19:33.827718    55 net.cpp:122] Setting up mnist\r\n",
      "I0922 12:19:33.827764    55 net.cpp:129] Top shape: 100 1 28 28 (78400)\r\n",
      "I0922 12:19:33.827821    55 net.cpp:129] Top shape: 100 (100)\r\n",
      "I0922 12:19:33.827898    55 net.cpp:137] Memory required for data: 314000\r\n",
      "I0922 12:19:33.827984    55 layer_factory.hpp:77] Creating layer label_mnist_1_split\r\n",
      "I0922 12:19:33.828022    55 net.cpp:84] Creating Layer label_mnist_1_split\r\n",
      "I0922 12:19:33.828060    55 net.cpp:406] label_mnist_1_split <- label\r\n",
      "I0922 12:19:33.830238    55 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0\r\n",
      "I0922 12:19:33.830655    55 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1\r\n",
      "I0922 12:19:33.830700    55 net.cpp:122] Setting up label_mnist_1_split\r\n",
      "I0922 12:19:33.830736    55 net.cpp:129] Top shape: 100 (100)\r\n",
      "I0922 12:19:33.830791    55 net.cpp:129] Top shape: 100 (100)\r\n",
      "I0922 12:19:33.830914    55 net.cpp:137] Memory required for data: 314800\r\n",
      "I0922 12:19:33.830999    55 layer_factory.hpp:77] Creating layer conv1\r\n",
      "I0922 12:19:33.831166    55 net.cpp:84] Creating Layer conv1\r\n",
      "I0922 12:19:33.831203    55 net.cpp:406] conv1 <- data\r\n",
      "I0922 12:19:33.831250    55 net.cpp:380] conv1 -> conv1\r\n",
      "I0922 12:19:33.831449    55 net.cpp:122] Setting up conv1\r\n",
      "I0922 12:19:33.831519    55 net.cpp:129] Top shape: 100 20 24 24 (1152000)\r\n",
      "I0922 12:19:33.831720    55 net.cpp:137] Memory required for data: 4922800\r\n",
      "I0922 12:19:33.831773    55 layer_factory.hpp:77] Creating layer pool1\r\n",
      "I0922 12:19:33.831812    55 net.cpp:84] Creating Layer pool1\r\n",
      "I0922 12:19:33.832092    55 net.cpp:406] pool1 <- conv1\r\n",
      "I0922 12:19:33.832108    55 net.cpp:380] pool1 -> pool1\r\n",
      "I0922 12:19:33.832150    55 net.cpp:122] Setting up pool1\r\n",
      "I0922 12:19:33.832193    55 net.cpp:129] Top shape: 100 20 12 12 (288000)\r\n",
      "I0922 12:19:33.832248    55 net.cpp:137] Memory required for data: 6074800\r\n",
      "I0922 12:19:33.832473    55 layer_factory.hpp:77] Creating layer conv2\r\n",
      "I0922 12:19:33.832510    55 net.cpp:84] Creating Layer conv2\r\n",
      "I0922 12:19:33.832531    55 net.cpp:406] conv2 <- pool1\r\n",
      "I0922 12:19:33.832566    55 net.cpp:380] conv2 -> conv2\r\n",
      "I0922 12:19:33.833227    55 net.cpp:122] Setting up conv2\r\n",
      "I0922 12:19:33.833495    55 net.cpp:129] Top shape: 100 50 8 8 (320000)\r\n",
      "I0922 12:19:33.833560    55 net.cpp:137] Memory required for data: 7354800\r\n",
      "I0922 12:19:33.833714    55 layer_factory.hpp:77] Creating layer pool2\r\n",
      "I0922 12:19:33.833730    55 net.cpp:84] Creating Layer pool2\r\n",
      "I0922 12:19:33.833817    55 net.cpp:406] pool2 <- conv2\r\n",
      "I0922 12:19:33.833835    55 net.cpp:380] pool2 -> pool2\r\n",
      "I0922 12:19:33.834105    55 net.cpp:122] Setting up pool2\r\n",
      "I0922 12:19:33.834128    55 net.cpp:129] Top shape: 100 50 4 4 (80000)\r\n",
      "I0922 12:19:33.834165    55 net.cpp:137] Memory required for data: 7674800\r\n",
      "I0922 12:19:33.834184    55 layer_factory.hpp:77] Creating layer ip1\r\n",
      "I0922 12:19:33.834224    55 net.cpp:84] Creating Layer ip1\r\n",
      "I0922 12:19:33.834396    55 net.cpp:406] ip1 <- pool2\r\n",
      "I0922 12:19:33.834414    55 net.cpp:380] ip1 -> ip1\r\n",
      "I0922 12:19:33.836627    55 net.cpp:122] Setting up ip1\r\n",
      "I0922 12:19:33.836664    55 net.cpp:129] Top shape: 100 500 (50000)\r\n",
      "I0922 12:19:33.836674    55 net.cpp:137] Memory required for data: 7874800\r\n",
      "I0922 12:19:33.836716    55 layer_factory.hpp:77] Creating layer relu1\r\n",
      "I0922 12:19:33.836757    55 net.cpp:84] Creating Layer relu1\r\n",
      "I0922 12:19:33.836777    55 net.cpp:406] relu1 <- ip1\r\n",
      "I0922 12:19:33.836809    55 net.cpp:367] relu1 -> ip1 (in-place)\r\n",
      "I0922 12:19:33.836827    55 net.cpp:122] Setting up relu1\r\n",
      "I0922 12:19:33.836838    55 net.cpp:129] Top shape: 100 500 (50000)\r\n",
      "I0922 12:19:33.836879    55 net.cpp:137] Memory required for data: 8074800\r\n",
      "I0922 12:19:33.836891    55 layer_factory.hpp:77] Creating layer ip2\r\n",
      "I0922 12:19:33.836982    55 net.cpp:84] Creating Layer ip2\r\n",
      "I0922 12:19:33.837003    55 net.cpp:406] ip2 <- ip1\r\n",
      "I0922 12:19:33.837040    55 net.cpp:380] ip2 -> ip2\r\n",
      "I0922 12:19:33.837107    55 net.cpp:122] Setting up ip2\r\n",
      "I0922 12:19:33.837143    55 net.cpp:129] Top shape: 100 10 (1000)\r\n",
      "I0922 12:19:33.837178    55 net.cpp:137] Memory required for data: 8078800\r\n",
      "I0922 12:19:33.837194    55 layer_factory.hpp:77] Creating layer ip2_ip2_0_split\r\n",
      "I0922 12:19:33.837229    55 net.cpp:84] Creating Layer ip2_ip2_0_split\r\n",
      "I0922 12:19:33.837239    55 net.cpp:406] ip2_ip2_0_split <- ip2\r\n",
      "I0922 12:19:33.837255    55 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_0\r\n",
      "I0922 12:19:33.837288    55 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_1\r\n",
      "I0922 12:19:33.837354    55 net.cpp:122] Setting up ip2_ip2_0_split\r\n",
      "I0922 12:19:33.837374    55 net.cpp:129] Top shape: 100 10 (1000)\r\n",
      "I0922 12:19:33.837394    55 net.cpp:129] Top shape: 100 10 (1000)\r\n",
      "I0922 12:19:33.837453    55 net.cpp:137] Memory required for data: 8086800\r\n",
      "I0922 12:19:33.837502    55 layer_factory.hpp:77] Creating layer accuracy\r\n",
      "I0922 12:19:33.837558    55 net.cpp:84] Creating Layer accuracy\r\n",
      "I0922 12:19:33.837635    55 net.cpp:406] accuracy <- ip2_ip2_0_split_0\r\n",
      "I0922 12:19:33.837652    55 net.cpp:406] accuracy <- label_mnist_1_split_0\r\n",
      "I0922 12:19:33.837695    55 net.cpp:380] accuracy -> accuracy\r\n",
      "I0922 12:19:33.837734    55 net.cpp:122] Setting up accuracy\r\n",
      "I0922 12:19:33.837793    55 net.cpp:129] Top shape: (1)\r\n",
      "I0922 12:19:33.837834    55 net.cpp:137] Memory required for data: 8086804\r\n",
      "I0922 12:19:33.837873    55 layer_factory.hpp:77] Creating layer loss\r\n",
      "I0922 12:19:33.837914    55 net.cpp:84] Creating Layer loss\r\n",
      "I0922 12:19:33.837929    55 net.cpp:406] loss <- ip2_ip2_0_split_1\r\n",
      "I0922 12:19:33.837968    55 net.cpp:406] loss <- label_mnist_1_split_1\r\n",
      "I0922 12:19:33.838009    55 net.cpp:380] loss -> loss\r\n",
      "I0922 12:19:33.838032    55 layer_factory.hpp:77] Creating layer loss\r\n",
      "I0922 12:19:33.838186    55 net.cpp:122] Setting up loss\r\n",
      "I0922 12:19:33.838234    55 net.cpp:129] Top shape: (1)\r\n",
      "I0922 12:19:33.838279    55 net.cpp:132]     with loss weight 1\r\n",
      "I0922 12:19:33.838342    55 net.cpp:137] Memory required for data: 8086808\r\n",
      "I0922 12:19:33.838366    55 net.cpp:198] loss needs backward computation.\r\n",
      "I0922 12:19:33.838407    55 net.cpp:200] accuracy does not need backward computation.\r\n",
      "I0922 12:19:33.838459    55 net.cpp:198] ip2_ip2_0_split needs backward computation.\r\n",
      "I0922 12:19:33.838506    55 net.cpp:198] ip2 needs backward computation.\r\n",
      "I0922 12:19:33.838533    55 net.cpp:198] relu1 needs backward computation.\r\n",
      "I0922 12:19:33.838557    55 net.cpp:198] ip1 needs backward computation.\r\n",
      "I0922 12:19:33.838615    55 net.cpp:198] pool2 needs backward computation.\r\n",
      "I0922 12:19:33.838666    55 net.cpp:198] conv2 needs backward computation.\r\n",
      "I0922 12:19:33.838714    55 net.cpp:198] pool1 needs backward computation.\r\n",
      "I0922 12:19:33.838755    55 net.cpp:198] conv1 needs backward computation.\r\n",
      "I0922 12:19:33.838773    55 net.cpp:200] label_mnist_1_split does not need backward computation.\r\n",
      "I0922 12:19:33.838814    55 net.cpp:200] mnist does not need backward computation.\r\n",
      "I0922 12:19:33.838830    55 net.cpp:242] This network produces output accuracy\r\n",
      "I0922 12:19:33.838841    55 net.cpp:242] This network produces output loss\r\n",
      "I0922 12:19:33.838918    55 net.cpp:255] Network initialization done.\r\n",
      "I0922 12:19:33.839071    55 solver.cpp:56] Solver scaffolding done.\r\n",
      "I0922 12:19:33.839145    55 caffe.cpp:248] Starting Optimization\r\n",
      "I0922 12:19:33.839181    55 solver.cpp:272] Solving LeNet\r\n",
      "I0922 12:19:33.839195    55 solver.cpp:273] Learning Rate Policy: inv\r\n",
      "I0922 12:19:33.839874    55 solver.cpp:330] Iteration 0, Testing net (#0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0922 12:19:43.456387    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:19:43.848264    55 solver.cpp:397]     Test net output #0: accuracy = 0.1348\n",
      "I0922 12:19:43.848340    55 solver.cpp:397]     Test net output #1: loss = 2.28972 (* 1 = 2.28972 loss)\n",
      "I0922 12:19:43.973563    55 solver.cpp:218] Iteration 0 (0 iter/s, 10.134s/100 iters), loss = 2.2586\n",
      "I0922 12:19:43.973678    55 solver.cpp:237]     Train net output #0: loss = 2.2586 (* 1 = 2.2586 loss)\n",
      "I0922 12:19:43.973712    55 sgd_solver.cpp:105] Iteration 0, lr = 0.01\n",
      "I0922 12:19:50.941735    55 solver.cpp:218] Iteration 100 (14.3513 iter/s, 6.968s/100 iters), loss = 0.163931\n",
      "I0922 12:19:50.941851    55 solver.cpp:237]     Train net output #0: loss = 0.163931 (* 1 = 0.163931 loss)\n",
      "I0922 12:19:50.941893    55 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565\n",
      "I0922 12:19:57.815150    55 solver.cpp:218] Iteration 200 (14.5497 iter/s, 6.873s/100 iters), loss = 0.144772\n",
      "I0922 12:19:57.815258    55 solver.cpp:237]     Train net output #0: loss = 0.144772 (* 1 = 0.144772 loss)\n",
      "I0922 12:19:57.815317    55 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258\n",
      "I0922 12:20:05.097005    55 solver.cpp:218] Iteration 300 (13.7344 iter/s, 7.281s/100 iters), loss = 0.18527\n",
      "I0922 12:20:05.097581    55 solver.cpp:237]     Train net output #0: loss = 0.18527 (* 1 = 0.18527 loss)\n",
      "I0922 12:20:05.097604    55 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075\n",
      "I0922 12:20:12.105326    55 solver.cpp:218] Iteration 400 (14.2714 iter/s, 7.007s/100 iters), loss = 0.0783607\n",
      "I0922 12:20:12.105412    55 solver.cpp:237]     Train net output #0: loss = 0.0783608 (* 1 = 0.0783608 loss)\n",
      "I0922 12:20:12.105439    55 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013\n",
      "I0922 12:20:18.904476    55 solver.cpp:330] Iteration 500, Testing net (#0)\n",
      "I0922 12:20:23.144196    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:20:23.321873    55 solver.cpp:397]     Test net output #0: accuracy = 0.9731\n",
      "I0922 12:20:23.321951    55 solver.cpp:397]     Test net output #1: loss = 0.0846844 (* 1 = 0.0846844 loss)\n",
      "I0922 12:20:23.392233    55 solver.cpp:218] Iteration 500 (8.86053 iter/s, 11.286s/100 iters), loss = 0.133861\n",
      "I0922 12:20:23.392330    55 solver.cpp:237]     Train net output #0: loss = 0.133861 (* 1 = 0.133861 loss)\n",
      "I0922 12:20:23.392385    55 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069\n",
      "I0922 12:20:30.731307    55 solver.cpp:218] Iteration 600 (13.6277 iter/s, 7.338s/100 iters), loss = 0.090068\n",
      "I0922 12:20:30.731479    55 solver.cpp:237]     Train net output #0: loss = 0.0900681 (* 1 = 0.0900681 loss)\n",
      "I0922 12:20:30.731513    55 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724\n",
      "I0922 12:20:37.753757    55 solver.cpp:218] Iteration 700 (14.241 iter/s, 7.022s/100 iters), loss = 0.135328\n",
      "I0922 12:20:37.754187    55 solver.cpp:237]     Train net output #0: loss = 0.135328 (* 1 = 0.135328 loss)\n",
      "I0922 12:20:37.754276    55 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522\n",
      "I0922 12:20:44.859338    55 solver.cpp:218] Iteration 800 (14.0746 iter/s, 7.105s/100 iters), loss = 0.250472\n",
      "I0922 12:20:44.859480    55 solver.cpp:237]     Train net output #0: loss = 0.250472 (* 1 = 0.250472 loss)\n",
      "I0922 12:20:44.859526    55 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913\n",
      "I0922 12:20:51.997066    55 solver.cpp:218] Iteration 900 (14.0115 iter/s, 7.137s/100 iters), loss = 0.184417\n",
      "I0922 12:20:51.997151    55 solver.cpp:237]     Train net output #0: loss = 0.184417 (* 1 = 0.184417 loss)\n",
      "I0922 12:20:51.997195    55 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411\n",
      "I0922 12:20:54.295671    57 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:20:59.330440    55 solver.cpp:330] Iteration 1000, Testing net (#0)\n",
      "I0922 12:21:04.289774    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:21:04.497638    55 solver.cpp:397]     Test net output #0: accuracy = 0.9815\n",
      "I0922 12:21:04.497728    55 solver.cpp:397]     Test net output #1: loss = 0.0575802 (* 1 = 0.0575802 loss)\n",
      "I0922 12:21:04.576030    55 solver.cpp:218] Iteration 1000 (7.95039 iter/s, 12.578s/100 iters), loss = 0.0859196\n",
      "I0922 12:21:04.576182    55 solver.cpp:237]     Train net output #0: loss = 0.0859197 (* 1 = 0.0859197 loss)\n",
      "I0922 12:21:04.576210    55 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012\n",
      "I0922 12:21:11.844985    55 solver.cpp:218] Iteration 1100 (13.7589 iter/s, 7.268s/100 iters), loss = 0.00543769\n",
      "I0922 12:21:11.845393    55 solver.cpp:237]     Train net output #0: loss = 0.00543783 (* 1 = 0.00543783 loss)\n",
      "I0922 12:21:11.845415    55 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715\n",
      "I0922 12:21:18.472733    55 solver.cpp:218] Iteration 1200 (15.0898 iter/s, 6.627s/100 iters), loss = 0.0149168\n",
      "I0922 12:21:18.472818    55 solver.cpp:237]     Train net output #0: loss = 0.0149169 (* 1 = 0.0149169 loss)\n",
      "I0922 12:21:18.472839    55 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515\n",
      "I0922 12:21:25.663897    55 solver.cpp:218] Iteration 1300 (13.9063 iter/s, 7.191s/100 iters), loss = 0.00902453\n",
      "I0922 12:21:25.663992    55 solver.cpp:237]     Train net output #0: loss = 0.00902469 (* 1 = 0.00902469 loss)\n",
      "I0922 12:21:25.664021    55 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412\n",
      "I0922 12:21:33.079881    55 solver.cpp:218] Iteration 1400 (13.4862 iter/s, 7.415s/100 iters), loss = 0.0108536\n",
      "I0922 12:21:33.079974    55 solver.cpp:237]     Train net output #0: loss = 0.0108538 (* 1 = 0.0108538 loss)\n",
      "I0922 12:21:33.079991    55 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403\n",
      "I0922 12:21:40.055682    55 solver.cpp:330] Iteration 1500, Testing net (#0)\n",
      "I0922 12:21:44.582872    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:21:44.795277    55 solver.cpp:397]     Test net output #0: accuracy = 0.9843\n",
      "I0922 12:21:44.795357    55 solver.cpp:397]     Test net output #1: loss = 0.0474835 (* 1 = 0.0474835 loss)\n",
      "I0922 12:21:44.844995    55 solver.cpp:218] Iteration 1500 (8.49979 iter/s, 11.765s/100 iters), loss = 0.0755878\n",
      "I0922 12:21:44.845089    55 solver.cpp:237]     Train net output #0: loss = 0.075588 (* 1 = 0.075588 loss)\n",
      "I0922 12:21:44.845114    55 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485\n",
      "I0922 12:21:52.578522    55 solver.cpp:218] Iteration 1600 (12.9316 iter/s, 7.733s/100 iters), loss = 0.124982\n",
      "I0922 12:21:52.578619    55 solver.cpp:237]     Train net output #0: loss = 0.124982 (* 1 = 0.124982 loss)\n",
      "I0922 12:21:52.578649    55 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657\n",
      "I0922 12:22:00.381742    55 solver.cpp:218] Iteration 1700 (12.8156 iter/s, 7.803s/100 iters), loss = 0.0142311\n",
      "I0922 12:22:00.381831    55 solver.cpp:237]     Train net output #0: loss = 0.0142312 (* 1 = 0.0142312 loss)\n",
      "I0922 12:22:00.381846    55 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916\n",
      "I0922 12:22:07.689052    55 solver.cpp:218] Iteration 1800 (13.6855 iter/s, 7.307s/100 iters), loss = 0.0157545\n",
      "I0922 12:22:07.689144    55 solver.cpp:237]     Train net output #0: loss = 0.0157547 (* 1 = 0.0157547 loss)\n",
      "I0922 12:22:07.689168    55 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326\n",
      "I0922 12:22:12.965308    57 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:22:15.308568    55 solver.cpp:218] Iteration 1900 (13.1251 iter/s, 7.619s/100 iters), loss = 0.127581\n",
      "I0922 12:22:15.309056    55 solver.cpp:237]     Train net output #0: loss = 0.127581 (* 1 = 0.127581 loss)\n",
      "I0922 12:22:15.309082    55 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687\n",
      "I0922 12:22:23.446267    55 solver.cpp:330] Iteration 2000, Testing net (#0)\n",
      "I0922 12:22:28.128201    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:22:28.307675    55 solver.cpp:397]     Test net output #0: accuracy = 0.9862\n",
      "I0922 12:22:28.307770    55 solver.cpp:397]     Test net output #1: loss = 0.0420194 (* 1 = 0.0420194 loss)\n",
      "I0922 12:22:28.377740    55 solver.cpp:218] Iteration 2000 (7.65228 iter/s, 13.068s/100 iters), loss = 0.00787173\n",
      "I0922 12:22:28.377835    55 solver.cpp:237]     Train net output #0: loss = 0.00787196 (* 1 = 0.00787196 loss)\n",
      "I0922 12:22:28.377858    55 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196\n",
      "I0922 12:22:35.874765    55 solver.cpp:218] Iteration 2100 (13.3404 iter/s, 7.496s/100 iters), loss = 0.0388254\n",
      "I0922 12:22:35.874843    55 solver.cpp:237]     Train net output #0: loss = 0.0388257 (* 1 = 0.0388257 loss)\n",
      "I0922 12:22:35.874862    55 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0922 12:22:43.540994    55 solver.cpp:218] Iteration 2200 (13.0446 iter/s, 7.666s/100 iters), loss = 0.0125064\n",
      "I0922 12:22:43.541155    55 solver.cpp:237]     Train net output #0: loss = 0.0125067 (* 1 = 0.0125067 loss)\n",
      "I0922 12:22:43.541204    55 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145\n",
      "I0922 12:22:51.573444    55 solver.cpp:218] Iteration 2300 (12.4502 iter/s, 8.032s/100 iters), loss = 0.0791962\n",
      "I0922 12:22:51.573892    55 solver.cpp:237]     Train net output #0: loss = 0.0791965 (* 1 = 0.0791965 loss)\n",
      "I0922 12:22:51.573917    55 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192\n",
      "I0922 12:22:59.050201    55 solver.cpp:218] Iteration 2400 (13.3761 iter/s, 7.476s/100 iters), loss = 0.0095124\n",
      "I0922 12:22:59.050292    55 solver.cpp:237]     Train net output #0: loss = 0.00951269 (* 1 = 0.00951269 loss)\n",
      "I0922 12:22:59.050315    55 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008\n",
      "I0922 12:23:06.363159    55 solver.cpp:330] Iteration 2500, Testing net (#0)\n",
      "I0922 12:23:11.041790    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:23:11.249943    55 solver.cpp:397]     Test net output #0: accuracy = 0.9858\n",
      "I0922 12:23:11.250046    55 solver.cpp:397]     Test net output #1: loss = 0.0479777 (* 1 = 0.0479777 loss)\n",
      "I0922 12:23:11.328394    55 solver.cpp:218] Iteration 2500 (8.14465 iter/s, 12.278s/100 iters), loss = 0.0300292\n",
      "I0922 12:23:11.328559    55 solver.cpp:237]     Train net output #0: loss = 0.0300295 (* 1 = 0.0300295 loss)\n",
      "I0922 12:23:11.328619    55 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897\n",
      "I0922 12:23:19.237771    55 solver.cpp:218] Iteration 2600 (12.6438 iter/s, 7.909s/100 iters), loss = 0.0841021\n",
      "I0922 12:23:19.237864    55 solver.cpp:237]     Train net output #0: loss = 0.0841024 (* 1 = 0.0841024 loss)\n",
      "I0922 12:23:19.237893    55 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857\n",
      "I0922 12:23:26.970691    55 solver.cpp:218] Iteration 2700 (12.9333 iter/s, 7.732s/100 iters), loss = 0.0301914\n",
      "I0922 12:23:26.970969    55 solver.cpp:237]     Train net output #0: loss = 0.0301917 (* 1 = 0.0301917 loss)\n",
      "I0922 12:23:26.971101    55 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886\n",
      "I0922 12:23:34.848246    55 solver.cpp:218] Iteration 2800 (12.6952 iter/s, 7.877s/100 iters), loss = 0.00345118\n",
      "I0922 12:23:34.848372    55 solver.cpp:237]     Train net output #0: loss = 0.00345147 (* 1 = 0.00345147 loss)\n",
      "I0922 12:23:34.848397    55 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984\n",
      "I0922 12:23:35.477730    57 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:23:42.977603    55 solver.cpp:218] Iteration 2900 (12.3016 iter/s, 8.129s/100 iters), loss = 0.0340366\n",
      "I0922 12:23:42.977692    55 solver.cpp:237]     Train net output #0: loss = 0.0340369 (* 1 = 0.0340369 loss)\n",
      "I0922 12:23:42.977723    55 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148\n",
      "I0922 12:23:50.785799    55 solver.cpp:330] Iteration 3000, Testing net (#0)\n",
      "I0922 12:23:55.336182    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:23:55.526290    55 solver.cpp:397]     Test net output #0: accuracy = 0.9879\n",
      "I0922 12:23:55.526372    55 solver.cpp:397]     Test net output #1: loss = 0.0368103 (* 1 = 0.0368103 loss)\n",
      "I0922 12:23:55.597846    55 solver.cpp:218] Iteration 3000 (7.92393 iter/s, 12.62s/100 iters), loss = 0.00672284\n",
      "I0922 12:23:55.597935    55 solver.cpp:237]     Train net output #0: loss = 0.00672315 (* 1 = 0.00672315 loss)\n",
      "I0922 12:23:55.597965    55 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377\n",
      "I0922 12:24:04.068974    55 solver.cpp:218] Iteration 3100 (11.805 iter/s, 8.471s/100 iters), loss = 0.0120085\n",
      "I0922 12:24:04.069425    55 solver.cpp:237]     Train net output #0: loss = 0.0120088 (* 1 = 0.0120088 loss)\n",
      "I0922 12:24:04.069458    55 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667\n",
      "I0922 12:24:12.562443    55 solver.cpp:218] Iteration 3200 (11.7744 iter/s, 8.493s/100 iters), loss = 0.00502386\n",
      "I0922 12:24:12.562542    55 solver.cpp:237]     Train net output #0: loss = 0.00502419 (* 1 = 0.00502419 loss)\n",
      "I0922 12:24:12.562570    55 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025\n",
      "I0922 12:24:20.551311    55 solver.cpp:218] Iteration 3300 (12.5188 iter/s, 7.988s/100 iters), loss = 0.0360561\n",
      "I0922 12:24:20.551565    55 solver.cpp:237]     Train net output #0: loss = 0.0360565 (* 1 = 0.0360565 loss)\n",
      "I0922 12:24:20.551626    55 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442\n",
      "I0922 12:24:28.714079    55 solver.cpp:218] Iteration 3400 (12.2519 iter/s, 8.162s/100 iters), loss = 0.0122127\n",
      "I0922 12:24:28.714169    55 solver.cpp:237]     Train net output #0: loss = 0.012213 (* 1 = 0.012213 loss)\n",
      "I0922 12:24:28.714190    55 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918\n",
      "I0922 12:24:37.700073    55 solver.cpp:330] Iteration 3500, Testing net (#0)\n",
      "I0922 12:24:42.873387    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:24:43.081804    55 solver.cpp:397]     Test net output #0: accuracy = 0.9875\n",
      "I0922 12:24:43.081894    55 solver.cpp:397]     Test net output #1: loss = 0.0387602 (* 1 = 0.0387602 loss)\n",
      "I0922 12:24:43.166131    55 solver.cpp:218] Iteration 3500 (6.91994 iter/s, 14.451s/100 iters), loss = 0.00788051\n",
      "I0922 12:24:43.166222    55 solver.cpp:237]     Train net output #0: loss = 0.00788086 (* 1 = 0.00788086 loss)\n",
      "I0922 12:24:43.166244    55 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454\n",
      "I0922 12:24:51.292856    55 solver.cpp:218] Iteration 3600 (12.3062 iter/s, 8.126s/100 iters), loss = 0.0248109\n",
      "I0922 12:24:51.292953    55 solver.cpp:237]     Train net output #0: loss = 0.0248112 (* 1 = 0.0248112 loss)\n",
      "I0922 12:24:51.292982    55 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046\n",
      "I0922 12:24:59.389187    55 solver.cpp:218] Iteration 3700 (12.3518 iter/s, 8.096s/100 iters), loss = 0.0277814\n",
      "I0922 12:24:59.389277    55 solver.cpp:237]     Train net output #0: loss = 0.0277817 (* 1 = 0.0277817 loss)\n",
      "I0922 12:24:59.389307    55 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695\n",
      "I0922 12:25:03.397148    57 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:25:08.177465    55 solver.cpp:218] Iteration 3800 (11.3792 iter/s, 8.788s/100 iters), loss = 0.0114432\n",
      "I0922 12:25:08.177729    55 solver.cpp:237]     Train net output #0: loss = 0.0114436 (* 1 = 0.0114436 loss)\n",
      "I0922 12:25:08.177755    55 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854\n",
      "I0922 12:25:16.287588    55 solver.cpp:218] Iteration 3900 (12.332 iter/s, 8.109s/100 iters), loss = 0.0426854\n",
      "I0922 12:25:16.287688    55 solver.cpp:237]     Train net output #0: loss = 0.0426857 (* 1 = 0.0426857 loss)\n",
      "I0922 12:25:16.287712    55 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158\n",
      "I0922 12:25:23.969728    55 solver.cpp:330] Iteration 4000, Testing net (#0)\n",
      "I0922 12:25:28.943703    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:25:29.144829    55 solver.cpp:397]     Test net output #0: accuracy = 0.9903\n",
      "I0922 12:25:29.144917    55 solver.cpp:397]     Test net output #1: loss = 0.0302677 (* 1 = 0.0302677 loss)\n",
      "I0922 12:25:29.222833    55 solver.cpp:218] Iteration 4000 (7.73096 iter/s, 12.935s/100 iters), loss = 0.0195412\n",
      "I0922 12:25:29.222927    55 solver.cpp:237]     Train net output #0: loss = 0.0195416 (* 1 = 0.0195416 loss)\n",
      "I0922 12:25:29.222954    55 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697\n",
      "I0922 12:25:37.418279    55 solver.cpp:218] Iteration 4100 (12.2026 iter/s, 8.195s/100 iters), loss = 0.0185847\n",
      "I0922 12:25:37.418380    55 solver.cpp:237]     Train net output #0: loss = 0.0185851 (* 1 = 0.0185851 loss)\n",
      "I0922 12:25:37.418404    55 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833\n",
      "I0922 12:25:45.125355    55 solver.cpp:218] Iteration 4200 (12.9769 iter/s, 7.706s/100 iters), loss = 0.00976749\n",
      "I0922 12:25:45.125730    55 solver.cpp:237]     Train net output #0: loss = 0.00976782 (* 1 = 0.00976782 loss)\n",
      "I0922 12:25:45.125763    55 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748\n",
      "I0922 12:25:52.771225    55 solver.cpp:218] Iteration 4300 (13.0804 iter/s, 7.645s/100 iters), loss = 0.0665898\n",
      "I0922 12:25:52.771443    55 solver.cpp:237]     Train net output #0: loss = 0.0665901 (* 1 = 0.0665901 loss)\n",
      "I0922 12:25:52.771473    55 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0922 12:26:00.443588    55 solver.cpp:218] Iteration 4400 (13.0344 iter/s, 7.672s/100 iters), loss = 0.0324321\n",
      "I0922 12:26:00.443711    55 solver.cpp:237]     Train net output #0: loss = 0.0324324 (* 1 = 0.0324324 loss)\n",
      "I0922 12:26:00.443747    55 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726\n",
      "I0922 12:26:08.450505    55 solver.cpp:330] Iteration 4500, Testing net (#0)\n",
      "I0922 12:26:13.637487    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:26:13.842031    55 solver.cpp:397]     Test net output #0: accuracy = 0.9891\n",
      "I0922 12:26:13.842119    55 solver.cpp:397]     Test net output #1: loss = 0.0331697 (* 1 = 0.0331697 loss)\n",
      "I0922 12:26:13.925824    55 solver.cpp:218] Iteration 4500 (7.4173 iter/s, 13.482s/100 iters), loss = 0.00308987\n",
      "I0922 12:26:13.925925    55 solver.cpp:237]     Train net output #0: loss = 0.00309021 (* 1 = 0.00309021 loss)\n",
      "I0922 12:26:13.925953    55 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788\n",
      "I0922 12:26:21.925227    55 solver.cpp:218] Iteration 4600 (12.5016 iter/s, 7.999s/100 iters), loss = 0.0196034\n",
      "I0922 12:26:21.925581    55 solver.cpp:237]     Train net output #0: loss = 0.0196037 (* 1 = 0.0196037 loss)\n",
      "I0922 12:26:21.925611    55 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897\n",
      "I0922 12:26:28.629056    57 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:26:29.990090    55 solver.cpp:218] Iteration 4700 (12.4008 iter/s, 8.064s/100 iters), loss = 0.00718209\n",
      "I0922 12:26:29.990190    55 solver.cpp:237]     Train net output #0: loss = 0.00718243 (* 1 = 0.00718243 loss)\n",
      "I0922 12:26:29.990238    55 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052\n",
      "I0922 12:26:37.987792    55 solver.cpp:218] Iteration 4800 (12.5047 iter/s, 7.997s/100 iters), loss = 0.0136216\n",
      "I0922 12:26:37.987890    55 solver.cpp:237]     Train net output #0: loss = 0.013622 (* 1 = 0.013622 loss)\n",
      "I0922 12:26:37.987915    55 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253\n",
      "I0922 12:26:45.662519    55 solver.cpp:218] Iteration 4900 (13.031 iter/s, 7.674s/100 iters), loss = 0.00748517\n",
      "I0922 12:26:45.662614    55 solver.cpp:237]     Train net output #0: loss = 0.00748551 (* 1 = 0.00748551 loss)\n",
      "I0922 12:26:45.662642    55 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498\n",
      "I0922 12:26:53.221694    55 solver.cpp:447] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel\n",
      "I0922 12:26:53.228698    55 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate\n",
      "I0922 12:26:53.232223    55 solver.cpp:330] Iteration 5000, Testing net (#0)\n",
      "I0922 12:26:57.853986    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:26:58.044764    55 solver.cpp:397]     Test net output #0: accuracy = 0.9897\n",
      "I0922 12:26:58.044852    55 solver.cpp:397]     Test net output #1: loss = 0.0326308 (* 1 = 0.0326308 loss)\n",
      "I0922 12:26:58.122352    55 solver.cpp:218] Iteration 5000 (8.02633 iter/s, 12.459s/100 iters), loss = 0.0327151\n",
      "I0922 12:26:58.122453    55 solver.cpp:237]     Train net output #0: loss = 0.0327154 (* 1 = 0.0327154 loss)\n",
      "I0922 12:26:58.122470    55 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788\n",
      "I0922 12:27:05.939940    55 solver.cpp:218] Iteration 5100 (12.7926 iter/s, 7.817s/100 iters), loss = 0.019584\n",
      "I0922 12:27:05.940033    55 solver.cpp:237]     Train net output #0: loss = 0.0195844 (* 1 = 0.0195844 loss)\n",
      "I0922 12:27:05.940049    55 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412\n",
      "I0922 12:27:13.790732    55 solver.cpp:218] Iteration 5200 (12.7389 iter/s, 7.85s/100 iters), loss = 0.00653893\n",
      "I0922 12:27:13.790845    55 solver.cpp:237]     Train net output #0: loss = 0.0065393 (* 1 = 0.0065393 loss)\n",
      "I0922 12:27:13.790880    55 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495\n",
      "I0922 12:27:21.585945    55 solver.cpp:218] Iteration 5300 (12.8287 iter/s, 7.795s/100 iters), loss = 0.00142868\n",
      "I0922 12:27:21.586045    55 solver.cpp:237]     Train net output #0: loss = 0.00142904 (* 1 = 0.00142904 loss)\n",
      "I0922 12:27:21.586076    55 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911\n",
      "I0922 12:27:29.588635    55 solver.cpp:218] Iteration 5400 (12.4969 iter/s, 8.002s/100 iters), loss = 0.00743452\n",
      "I0922 12:27:29.589205    55 solver.cpp:237]     Train net output #0: loss = 0.00743488 (* 1 = 0.00743488 loss)\n",
      "I0922 12:27:29.589228    55 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368\n",
      "I0922 12:27:37.057435    55 solver.cpp:330] Iteration 5500, Testing net (#0)\n",
      "I0922 12:27:41.707494    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:27:41.911521    55 solver.cpp:397]     Test net output #0: accuracy = 0.9896\n",
      "I0922 12:27:41.911608    55 solver.cpp:397]     Test net output #1: loss = 0.0340775 (* 1 = 0.0340775 loss)\n",
      "I0922 12:27:41.992287    55 solver.cpp:218] Iteration 5500 (8.06257 iter/s, 12.403s/100 iters), loss = 0.0155676\n",
      "I0922 12:27:41.992393    55 solver.cpp:237]     Train net output #0: loss = 0.015568 (* 1 = 0.015568 loss)\n",
      "I0922 12:27:41.992411    55 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865\n",
      "I0922 12:27:50.087074    55 solver.cpp:218] Iteration 5600 (12.3548 iter/s, 8.094s/100 iters), loss = 0.000938172\n",
      "I0922 12:27:50.087179    55 solver.cpp:237]     Train net output #0: loss = 0.000938548 (* 1 = 0.000938548 loss)\n",
      "I0922 12:27:50.087208    55 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402\n",
      "I0922 12:27:51.670182    57 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:27:57.983424    55 solver.cpp:218] Iteration 5700 (12.6646 iter/s, 7.896s/100 iters), loss = 0.00626544\n",
      "I0922 12:27:57.983536    55 solver.cpp:237]     Train net output #0: loss = 0.00626583 (* 1 = 0.00626583 loss)\n",
      "I0922 12:27:57.983682    55 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977\n",
      "I0922 12:28:05.828330    55 solver.cpp:218] Iteration 5800 (12.7486 iter/s, 7.844s/100 iters), loss = 0.0183468\n",
      "I0922 12:28:05.828707    55 solver.cpp:237]     Train net output #0: loss = 0.0183472 (* 1 = 0.0183472 loss)\n",
      "I0922 12:28:05.828737    55 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959\n",
      "I0922 12:28:14.187363    55 solver.cpp:218] Iteration 5900 (11.9646 iter/s, 8.358s/100 iters), loss = 0.00740388\n",
      "I0922 12:28:14.187570    55 solver.cpp:237]     Train net output #0: loss = 0.00740426 (* 1 = 0.00740426 loss)\n",
      "I0922 12:28:14.187595    55 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624\n",
      "I0922 12:28:22.203616    55 solver.cpp:330] Iteration 6000, Testing net (#0)\n",
      "I0922 12:28:27.150555    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:28:27.403750    55 solver.cpp:397]     Test net output #0: accuracy = 0.9911\n",
      "I0922 12:28:27.403834    55 solver.cpp:397]     Test net output #1: loss = 0.0290857 (* 1 = 0.0290857 loss)\n",
      "I0922 12:28:27.485491    55 solver.cpp:218] Iteration 6000 (7.52049 iter/s, 13.297s/100 iters), loss = 0.0034561\n",
      "I0922 12:28:27.485584    55 solver.cpp:237]     Train net output #0: loss = 0.0034565 (* 1 = 0.0034565 loss)\n",
      "I0922 12:28:27.485607    55 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927\n",
      "I0922 12:28:37.156703    55 solver.cpp:218] Iteration 6100 (10.3402 iter/s, 9.671s/100 iters), loss = 0.00259805\n",
      "I0922 12:28:37.157244    55 solver.cpp:237]     Train net output #0: loss = 0.00259844 (* 1 = 0.00259844 loss)\n",
      "I0922 12:28:37.157353    55 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965\n",
      "I0922 12:28:44.920595    55 solver.cpp:218] Iteration 6200 (12.8816 iter/s, 7.763s/100 iters), loss = 0.0073723\n",
      "I0922 12:28:44.920686    55 solver.cpp:237]     Train net output #0: loss = 0.00737269 (* 1 = 0.00737269 loss)\n",
      "I0922 12:28:44.920708    55 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408\n",
      "I0922 12:28:51.951515    55 solver.cpp:218] Iteration 6300 (14.2248 iter/s, 7.03s/100 iters), loss = 0.00638081\n",
      "I0922 12:28:51.951608    55 solver.cpp:237]     Train net output #0: loss = 0.00638121 (* 1 = 0.00638121 loss)\n",
      "I0922 12:28:51.951635    55 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201\n",
      "I0922 12:28:58.968138    55 solver.cpp:218] Iteration 6400 (14.2531 iter/s, 7.016s/100 iters), loss = 0.00704186\n",
      "I0922 12:28:58.968227    55 solver.cpp:237]     Train net output #0: loss = 0.00704226 (* 1 = 0.00704226 loss)\n",
      "I0922 12:28:58.968253    55 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0922 12:29:06.262691    55 solver.cpp:330] Iteration 6500, Testing net (#0)\n",
      "I0922 12:29:10.741101    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:29:10.922497    55 solver.cpp:397]     Test net output #0: accuracy = 0.989\n",
      "I0922 12:29:10.922562    55 solver.cpp:397]     Test net output #1: loss = 0.031654 (* 1 = 0.031654 loss)\n",
      "I0922 12:29:11.005513    55 solver.cpp:218] Iteration 6500 (8.30772 iter/s, 12.037s/100 iters), loss = 0.00813827\n",
      "I0922 12:29:11.005661    55 solver.cpp:237]     Train net output #0: loss = 0.00813868 (* 1 = 0.00813868 loss)\n",
      "I0922 12:29:11.005723    55 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689\n",
      "I0922 12:29:15.160471    57 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:29:18.093842    55 solver.cpp:218] Iteration 6600 (14.1084 iter/s, 7.088s/100 iters), loss = 0.0257869\n",
      "I0922 12:29:18.093946    55 solver.cpp:237]     Train net output #0: loss = 0.0257873 (* 1 = 0.0257873 loss)\n",
      "I0922 12:29:18.093981    55 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784\n",
      "I0922 12:29:25.635470    55 solver.cpp:218] Iteration 6700 (13.2608 iter/s, 7.541s/100 iters), loss = 0.00759862\n",
      "I0922 12:29:25.635567    55 solver.cpp:237]     Train net output #0: loss = 0.00759902 (* 1 = 0.00759902 loss)\n",
      "I0922 12:29:25.635597    55 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711\n",
      "I0922 12:29:33.559521    55 solver.cpp:218] Iteration 6800 (12.6215 iter/s, 7.923s/100 iters), loss = 0.00381856\n",
      "I0922 12:29:33.559615    55 solver.cpp:237]     Train net output #0: loss = 0.00381898 (* 1 = 0.00381898 loss)\n",
      "I0922 12:29:33.559639    55 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767\n",
      "I0922 12:29:40.654426    55 solver.cpp:218] Iteration 6900 (14.0964 iter/s, 7.094s/100 iters), loss = 0.00571613\n",
      "I0922 12:29:40.654525    55 solver.cpp:237]     Train net output #0: loss = 0.00571654 (* 1 = 0.00571654 loss)\n",
      "I0922 12:29:40.654543    55 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466\n",
      "I0922 12:29:48.423929    55 solver.cpp:330] Iteration 7000, Testing net (#0)\n",
      "I0922 12:29:53.593449    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:29:53.797504    55 solver.cpp:397]     Test net output #0: accuracy = 0.9909\n",
      "I0922 12:29:53.797595    55 solver.cpp:397]     Test net output #1: loss = 0.0294246 (* 1 = 0.0294246 loss)\n",
      "I0922 12:29:53.878597    55 solver.cpp:218] Iteration 7000 (7.56201 iter/s, 13.224s/100 iters), loss = 0.00393986\n",
      "I0922 12:29:53.878700    55 solver.cpp:237]     Train net output #0: loss = 0.00394026 (* 1 = 0.00394026 loss)\n",
      "I0922 12:29:53.878728    55 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681\n",
      "I0922 12:30:02.040318    55 solver.cpp:218] Iteration 7100 (12.2534 iter/s, 8.161s/100 iters), loss = 0.0126273\n",
      "I0922 12:30:02.040527    55 solver.cpp:237]     Train net output #0: loss = 0.0126277 (* 1 = 0.0126277 loss)\n",
      "I0922 12:30:02.040565    55 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733\n",
      "I0922 12:30:10.075119    55 solver.cpp:218] Iteration 7200 (12.4471 iter/s, 8.034s/100 iters), loss = 0.00488467\n",
      "I0922 12:30:10.075222    55 solver.cpp:237]     Train net output #0: loss = 0.00488508 (* 1 = 0.00488508 loss)\n",
      "I0922 12:30:10.075251    55 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815\n",
      "I0922 12:30:18.054968    55 solver.cpp:218] Iteration 7300 (12.5329 iter/s, 7.979s/100 iters), loss = 0.025281\n",
      "I0922 12:30:18.055119    55 solver.cpp:237]     Train net output #0: loss = 0.0252814 (* 1 = 0.0252814 loss)\n",
      "I0922 12:30:18.055169    55 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927\n",
      "I0922 12:30:25.497287    55 solver.cpp:218] Iteration 7400 (13.4372 iter/s, 7.442s/100 iters), loss = 0.0045682\n",
      "I0922 12:30:25.497632    55 solver.cpp:237]     Train net output #0: loss = 0.00456862 (* 1 = 0.00456862 loss)\n",
      "I0922 12:30:25.497654    55 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067\n",
      "I0922 12:30:32.541421    57 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:30:32.839216    55 solver.cpp:330] Iteration 7500, Testing net (#0)\n",
      "I0922 12:30:37.489938    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:30:37.695936    55 solver.cpp:397]     Test net output #0: accuracy = 0.99\n",
      "I0922 12:30:37.696177    55 solver.cpp:397]     Test net output #1: loss = 0.0332983 (* 1 = 0.0332983 loss)\n",
      "I0922 12:30:37.779794    55 solver.cpp:218] Iteration 7500 (8.142 iter/s, 12.282s/100 iters), loss = 0.00112057\n",
      "I0922 12:30:37.779937    55 solver.cpp:237]     Train net output #0: loss = 0.00112099 (* 1 = 0.00112099 loss)\n",
      "I0922 12:30:37.779978    55 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236\n",
      "I0922 12:30:45.891187    55 solver.cpp:218] Iteration 7600 (12.3289 iter/s, 8.111s/100 iters), loss = 0.00679544\n",
      "I0922 12:30:45.891400    55 solver.cpp:237]     Train net output #0: loss = 0.00679586 (* 1 = 0.00679586 loss)\n",
      "I0922 12:30:45.891454    55 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433\n",
      "I0922 12:30:53.837486    55 solver.cpp:218] Iteration 7700 (12.5849 iter/s, 7.946s/100 iters), loss = 0.022861\n",
      "I0922 12:30:53.837625    55 solver.cpp:237]     Train net output #0: loss = 0.0228614 (* 1 = 0.0228614 loss)\n",
      "I0922 12:30:53.837641    55 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658\n",
      "I0922 12:31:01.277742    55 solver.cpp:218] Iteration 7800 (13.4409 iter/s, 7.44s/100 iters), loss = 0.00417277\n",
      "I0922 12:31:01.277895    55 solver.cpp:237]     Train net output #0: loss = 0.00417319 (* 1 = 0.00417319 loss)\n",
      "I0922 12:31:01.277922    55 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911\n",
      "I0922 12:31:09.498667    55 solver.cpp:218] Iteration 7900 (12.1655 iter/s, 8.22s/100 iters), loss = 0.00292023\n",
      "I0922 12:31:09.498764    55 solver.cpp:237]     Train net output #0: loss = 0.00292064 (* 1 = 0.00292064 loss)\n",
      "I0922 12:31:09.498790    55 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619\n",
      "I0922 12:31:17.801779    55 solver.cpp:330] Iteration 8000, Testing net (#0)\n",
      "I0922 12:31:22.645382    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:31:22.837440    55 solver.cpp:397]     Test net output #0: accuracy = 0.9906\n",
      "I0922 12:31:22.837527    55 solver.cpp:397]     Test net output #1: loss = 0.0306797 (* 1 = 0.0306797 loss)\n",
      "I0922 12:31:22.913837    55 solver.cpp:218] Iteration 8000 (7.45434 iter/s, 13.415s/100 iters), loss = 0.0065931\n",
      "I0922 12:31:22.913959    55 solver.cpp:237]     Train net output #0: loss = 0.00659352 (* 1 = 0.00659352 loss)\n",
      "I0922 12:31:22.913992    55 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496\n",
      "I0922 12:31:30.831889    55 solver.cpp:218] Iteration 8100 (12.631 iter/s, 7.917s/100 iters), loss = 0.0133098\n",
      "I0922 12:31:30.831984    55 solver.cpp:237]     Train net output #0: loss = 0.0133102 (* 1 = 0.0133102 loss)\n",
      "I0922 12:31:30.832012    55 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827\n",
      "I0922 12:31:38.798184    55 solver.cpp:218] Iteration 8200 (12.5534 iter/s, 7.966s/100 iters), loss = 0.010121\n",
      "I0922 12:31:38.798467    55 solver.cpp:237]     Train net output #0: loss = 0.0101214 (* 1 = 0.0101214 loss)\n",
      "I0922 12:31:38.798534    55 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185\n",
      "I0922 12:31:46.384861    55 solver.cpp:218] Iteration 8300 (13.1822 iter/s, 7.586s/100 iters), loss = 0.0556084\n",
      "I0922 12:31:46.385056    55 solver.cpp:237]     Train net output #0: loss = 0.0556088 (* 1 = 0.0556088 loss)\n",
      "I0922 12:31:46.385082    55 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567\n",
      "I0922 12:31:54.094964    55 solver.cpp:218] Iteration 8400 (12.9719 iter/s, 7.709s/100 iters), loss = 0.00943517\n",
      "I0922 12:31:54.095068    55 solver.cpp:237]     Train net output #0: loss = 0.00943559 (* 1 = 0.00943559 loss)\n",
      "I0922 12:31:54.095099    55 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975\n",
      "I0922 12:31:57.019635    57 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:32:02.444461    55 solver.cpp:330] Iteration 8500, Testing net (#0)\n",
      "I0922 12:32:07.320369    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:32:07.519152    55 solver.cpp:397]     Test net output #0: accuracy = 0.991\n",
      "I0922 12:32:07.519237    55 solver.cpp:397]     Test net output #1: loss = 0.0299133 (* 1 = 0.0299133 loss)\n",
      "I0922 12:32:07.603468    55 solver.cpp:218] Iteration 8500 (7.40302 iter/s, 13.508s/100 iters), loss = 0.00533162\n",
      "I0922 12:32:07.603564    55 solver.cpp:237]     Train net output #0: loss = 0.00533204 (* 1 = 0.00533204 loss)\n",
      "I0922 12:32:07.603592    55 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0922 12:32:15.047472    55 solver.cpp:218] Iteration 8600 (13.4354 iter/s, 7.443s/100 iters), loss = 0.000947524\n",
      "I0922 12:32:15.047902    55 solver.cpp:237]     Train net output #0: loss = 0.000947939 (* 1 = 0.000947939 loss)\n",
      "I0922 12:32:15.047924    55 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864\n",
      "I0922 12:32:22.978206    55 solver.cpp:218] Iteration 8700 (12.6103 iter/s, 7.93s/100 iters), loss = 0.00218642\n",
      "I0922 12:32:22.978315    55 solver.cpp:237]     Train net output #0: loss = 0.00218684 (* 1 = 0.00218684 loss)\n",
      "I0922 12:32:22.978338    55 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344\n",
      "I0922 12:32:32.137571    55 solver.cpp:218] Iteration 8800 (10.9182 iter/s, 9.159s/100 iters), loss = 0.00115453\n",
      "I0922 12:32:32.137715    55 solver.cpp:237]     Train net output #0: loss = 0.00115495 (* 1 = 0.00115495 loss)\n",
      "I0922 12:32:32.137758    55 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847\n",
      "I0922 12:32:40.785776    55 solver.cpp:218] Iteration 8900 (11.5634 iter/s, 8.648s/100 iters), loss = 0.000472186\n",
      "I0922 12:32:40.785874    55 solver.cpp:237]     Train net output #0: loss = 0.000472603 (* 1 = 0.000472603 loss)\n",
      "I0922 12:32:40.785904    55 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374\n",
      "I0922 12:32:50.212443    55 solver.cpp:330] Iteration 9000, Testing net (#0)\n",
      "I0922 12:32:55.709091    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:32:55.939709    55 solver.cpp:397]     Test net output #0: accuracy = 0.9905\n",
      "I0922 12:32:55.939796    55 solver.cpp:397]     Test net output #1: loss = 0.0308493 (* 1 = 0.0308493 loss)\n",
      "I0922 12:32:56.036805    55 solver.cpp:218] Iteration 9000 (6.55738 iter/s, 15.25s/100 iters), loss = 0.0147587\n",
      "I0922 12:32:56.036912    55 solver.cpp:237]     Train net output #0: loss = 0.0147591 (* 1 = 0.0147591 loss)\n",
      "I0922 12:32:56.036936    55 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924\n",
      "I0922 12:33:04.032011    55 solver.cpp:218] Iteration 9100 (12.5078 iter/s, 7.995s/100 iters), loss = 0.00757783\n",
      "I0922 12:33:04.032104    55 solver.cpp:237]     Train net output #0: loss = 0.00757824 (* 1 = 0.00757824 loss)\n",
      "I0922 12:33:04.032131    55 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496\n",
      "I0922 12:33:11.230573    55 solver.cpp:218] Iteration 9200 (13.8927 iter/s, 7.198s/100 iters), loss = 0.00355145\n",
      "I0922 12:33:11.230669    55 solver.cpp:237]     Train net output #0: loss = 0.00355186 (* 1 = 0.00355186 loss)\n",
      "I0922 12:33:11.230696    55 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309\n",
      "I0922 12:33:18.919220    55 solver.cpp:218] Iteration 9300 (13.0073 iter/s, 7.688s/100 iters), loss = 0.00612107\n",
      "I0922 12:33:18.919320    55 solver.cpp:237]     Train net output #0: loss = 0.00612148 (* 1 = 0.00612148 loss)\n",
      "I0922 12:33:18.919346    55 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706\n",
      "I0922 12:33:24.619587    57 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:33:27.043977    55 solver.cpp:218] Iteration 9400 (12.3092 iter/s, 8.124s/100 iters), loss = 0.0178828\n",
      "I0922 12:33:27.044034    55 solver.cpp:237]     Train net output #0: loss = 0.0178832 (* 1 = 0.0178832 loss)\n",
      "I0922 12:33:27.044095    55 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343\n",
      "I0922 12:33:34.750083    55 solver.cpp:330] Iteration 9500, Testing net (#0)\n",
      "I0922 12:33:39.932917    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:33:40.142515    55 solver.cpp:397]     Test net output #0: accuracy = 0.9893\n",
      "I0922 12:33:40.142629    55 solver.cpp:397]     Test net output #1: loss = 0.0361585 (* 1 = 0.0361585 loss)\n",
      "I0922 12:33:40.225430    55 solver.cpp:218] Iteration 9500 (7.58668 iter/s, 13.181s/100 iters), loss = 0.00291814\n",
      "I0922 12:33:40.225534    55 solver.cpp:237]     Train net output #0: loss = 0.00291855 (* 1 = 0.00291855 loss)\n",
      "I0922 12:33:40.225560    55 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002\n",
      "I0922 12:33:48.570083    55 solver.cpp:218] Iteration 9600 (11.9847 iter/s, 8.344s/100 iters), loss = 0.0019058\n",
      "I0922 12:33:48.570186    55 solver.cpp:237]     Train net output #0: loss = 0.0019062 (* 1 = 0.0019062 loss)\n",
      "I0922 12:33:48.570214    55 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682\n",
      "I0922 12:33:56.736477    55 solver.cpp:218] Iteration 9700 (12.2459 iter/s, 8.166s/100 iters), loss = 0.00244779\n",
      "I0922 12:33:56.736644    55 solver.cpp:237]     Train net output #0: loss = 0.00244819 (* 1 = 0.00244819 loss)\n",
      "I0922 12:33:56.736658    55 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382\n",
      "I0922 12:34:03.950951    55 solver.cpp:218] Iteration 9800 (13.8619 iter/s, 7.214s/100 iters), loss = 0.0135687\n",
      "I0922 12:34:03.951052    55 solver.cpp:237]     Train net output #0: loss = 0.013569 (* 1 = 0.013569 loss)\n",
      "I0922 12:34:03.951227    55 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102\n",
      "I0922 12:34:11.329879    55 solver.cpp:218] Iteration 9900 (13.5538 iter/s, 7.378s/100 iters), loss = 0.00391597\n",
      "I0922 12:34:11.329975    55 solver.cpp:237]     Train net output #0: loss = 0.00391636 (* 1 = 0.00391636 loss)\n",
      "I0922 12:34:11.330003    55 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843\n",
      "I0922 12:34:18.766832    55 solver.cpp:447] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel\n",
      "I0922 12:34:18.774550    55 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate\n",
      "I0922 12:34:18.809269    55 solver.cpp:310] Iteration 10000, loss = 0.00347144\n",
      "I0922 12:34:18.809345    55 solver.cpp:330] Iteration 10000, Testing net (#0)\n",
      "I0922 12:34:23.444114    58 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0922 12:34:23.635308    55 solver.cpp:397]     Test net output #0: accuracy = 0.9909\n",
      "I0922 12:34:23.635401    55 solver.cpp:397]     Test net output #1: loss = 0.0300156 (* 1 = 0.0300156 loss)\n",
      "I0922 12:34:23.635426    55 solver.cpp:315] Optimization Done.\n",
      "I0922 12:34:23.635447    55 caffe.cpp:259] Optimization Done.\n"
     ]
    }
   ],
   "source": [
    "!cd $CAFFE_ROOT && ./data/mnist/get_mnist.sh && ./examples/mnist/create_mnist.sh && \\\n",
    "  cat ./examples/mnist/lenet_solver.prototxt | sed -e 's/max_iter:\\s10000/max_iter: 3000/g' | sed -e 's/solver_mode:\\sGPU/solver_mode: CPU/g' > ./examples/mnist/lenet_solver.prototxt.cpu && \\\n",
    "  cat ./examples/mnist/lenet_solver.prototxt.cpu > ./examples/mnist/lenet_solver.prototxt && \\\n",
    "  ./examples/mnist/train_lenet.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
